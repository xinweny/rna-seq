bootstr.sd.vector[i] <- sd(tmp)
}
max(bootstr.sd.vector)
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
#### Linear modeling ####
runif(5, min=0, max=1) # Function for pseudorandom numbers, generates n numbers where the next number is dependent on the previous one (not truly random)
set.seed() # Sets the intial number (seed) which the runif() function depends on
#### Histogram of random numbers ####
hist(runif(100))
hist(runif(10000))
#### Normal distribution
# the larger the sample size, the more "normal" the curve
rnorm(100) # Generates n numbers dependent on the normal distribution curve
# Probability density function of the normal distribution
plot(density(rnorm(100))) # Normal distribution PDF, alternatively dnorm(100)
# Compare stochasticity (estimated vs. theoretical PDF)
lines(seq(from=-4, to=4, length=1000),
dnorm(seq(from=-4, to=4, length=1000)),
col=2)
#### Estimating the mean of a distribution ####
mu <- 0 # theoretical mean
sd <- 1
x <- rnorm(100, mean=mu, sd=sd)
m.est <- mean(x) # estimated mean
## standard error of the mean
# var(X1 + X2 + X3) = var(X1) + var(X2) + var(X3)
#var(kX) = k^2 * var(X), therefore...
se <- sd / sqrt(100)
# Estimating the standard error
N <- 1000
mean.vector <- numeric(N) # generates a vector of N elements
# Obtain the mean of normally distributed samples over N experimental runs
for (i in 1:N) {
tmp <- rnorm(100, mean=mu, sd=sd)
mean.vector[i] <- mean(tmp)
}
mean(mean.vector) # UNBIASEDNESS - the larger the no, of experimental runs, the mean tends to mu
# Larger sample size = smaller variability
plot(density(mean.vector))
sd(mean.vector) # the larger the sample size, the closer the sd tends to the theoretical value
## However, we need to know our observations are coming from a normal distribution with the corresponding parameters - hard to know if this is true in practice
#### BOOTSTRAP APPROACH ####
# Allows the estimation of standard error, even for very complex models
# Does not make any assumptions about the data!
## Bootstrap sample - set of samples from the original data WITH REPLACEMENT
boot.s <- sample(x=1:100, size=100, replace=T) # generates a bootstrap sample of the INDEXES of 100 samples, WITH REPLACEMENT (replace is F by default)
# to obtain the actual sample values, do x[sample(x=1:100, size=100, replace=T)]
table(boot.s) # see frequencies of each occurrence
# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
plot(density(bootstr.sd.vector))
sd(bootstr.sd.vector) # computing the standard error
#### Linear modeling ####
runif(5, min=0, max=1) # Function for pseudorandom numbers, generates n numbers where the next number is dependent on the previous one (not truly random)
set.seed() # Sets the intial number (seed) which the runif() function depends on
#### Histogram of random numbers ####
hist(runif(100))
hist(runif(10000))
#### Normal distribution
# the larger the sample size, the more "normal" the curve
rnorm(100) # Generates n numbers dependent on the normal distribution curve
# Probability density function of the normal distribution
plot(density(rnorm(100))) # Normal distribution PDF, alternatively dnorm(100)
# Compare stochasticity (estimated vs. theoretical PDF)
lines(seq(from=-4, to=4, length=1000),
dnorm(seq(from=-4, to=4, length=1000)),
col=2)
#### Estimating the mean of a distribution ####
mu <- 0 # theoretical mean
sd <- 1
x <- rnorm(100, mean=mu, sd=sd)
m.est <- mean(x) # estimated mean
## standard error of the mean
# var(X1 + X2 + X3) = var(X1) + var(X2) + var(X3)
#var(kX) = k^2 * var(X), therefore...
se <- sd / sqrt(100)
# Estimating the standard error
N <- 1000
mean.vector <- numeric(N) # generates a vector of N elements
# Obtain the mean of normally distributed samples over N experimental runs
for (i in 1:N) {
tmp <- rnorm(100, mean=mu, sd=sd)
mean.vector[i] <- mean(tmp)
}
mean(mean.vector) # UNBIASEDNESS - the larger the no, of experimental runs, the mean tends to mu
# Larger sample size = smaller variability
plot(density(mean.vector))
sd(mean.vector) # the larger the sample size, the closer the sd tends to the theoretical value
## However, we need to know our observations are coming from a normal distribution with the corresponding parameters - hard to know if this is true in practice
#### BOOTSTRAP APPROACH ####
# Allows the estimation of standard error, even for very complex models
# Does not make any assumptions about the data!
## Bootstrap sample - set of samples from the original data WITH REPLACEMENT
boot.s <- sample(x=1:100, size=100, replace=T) # generates a bootstrap sample of the INDEXES of 100 samples, WITH REPLACEMENT (replace is F by default)
# to obtain the actual sample values, do x[sample(x=1:100, size=100, replace=T)]
table(boot.s) # see frequencies of each occurrence
# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
#### Linear Modeling ####
runif(5, min=0, max=1) # Function for pseudorandom numbers, generates n numbers where the next number is dependent on the previous one (not truly random)
set.seed() # Sets the intial number (seed) which the runif() function depends on
#### Histogram of random numbers ####
hist(runif(100))
hist(runif(10000))
#### Normal distribution
# the larger the sample size, the more "normal" the curve
rnorm(100) # Generates n numbers dependent on the normal distribution curve
# Probability density function of the normal distribution
plot(density(rnorm(100))) # Normal distribution PDF, alternatively dnorm(100)
# Compare stochasticity (estimated vs. theoretical PDF)
lines(seq(from=-4, to=4, length=1000),
dnorm(seq(from=-4, to=4, length=1000)),
col=2)
#### Estimating the mean of a distribution ####
mu <- 0 # theoretical mean
sd <- 1
x <- rnorm(100, mean=mu, sd=sd)
m.est <- mean(x) # estimated mean
## standard error of the mean
# var(X1 + X2 + X3) = var(X1) + var(X2) + var(X3)
#var(kX) = k^2 * var(X), therefore...
se <- sd / sqrt(100)
# Estimating the standard error
N <- 1000
mean.vector <- numeric(N) # generates a vector of N elements
# Obtain the mean of normally distributed samples over N experimental runs
for (i in 1:N) {
tmp <- rnorm(100, mean=mu, sd=sd)
mean.vector[i] <- mean(tmp)
}
mean(mean.vector) # UNBIASEDNESS - the larger the no, of experimental runs, the mean tends to mu
# Larger sample size = smaller variability
plot(density(mean.vector))
sd(mean.vector) # the larger the sample size, the closer the sd tends to the theoretical value
## However, we need to know our observations are coming from a normal distribution with the corresponding parameters - hard to know if this is true in practice
#### BOOTSTRAP APPROACH ####
# Allows the estimation of standard error, even for very complex models
# Does not make any assumptions about the data!
## Bootstrap sample - set of samples from the original data WITH REPLACEMENT
boot.s <- sample(x=1:100, size=100, replace=T) # generates a bootstrap sample of the INDEXES of 100 samples, WITH REPLACEMENT (replace is F by default)
# to obtain the actual sample values, do x[sample(x=1:100, size=100, replace=T)]
table(boot.s) # see frequencies of each occurrence
# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- 1
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
#### Linear Modeling ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
model.matrix(~er) # gene
model.matrix(~er)
model.matrix(~er + dose)
model.matrix(~er * dose)
modeling drug trial results
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
# generating a design matrix of ~independent variables
# syntax: dependent~independent variables
model.matrix(~er) # estrogen effect only
model.matrix(~er + dose) # estrogen and dose effect, without interaction
X <- model.matrix(~er * dose) # estrogen and dose effect, with interaction
beta <- x(beta0, beta.er, beta.dose) # vector of parameters (must match order in design matrix!)
Y <- X %*% beta # syntax: %*% - matrix multiplication
plot(dose, Y)
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
# generating a design matrix of ~independent variables
# syntax: dependent~independent variables
model.matrix(~er) # estrogen effect only
model.matrix(~er + dose) # estrogen and dose effect, without interaction
X <- model.matrix(~er * dose) # estrogen and dose effect, with interaction
beta <- c(beta0, beta.er, beta.dose) # vector of parameters (must match order in design matrix!)
Y <- X %*% beta # syntax: %*% - matrix multiplication
plot(dose, Y)
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
# generating a design matrix of ~independent variables
# syntax: dependent~independent variables
model.matrix(~er) # estrogen effect only
X <- model.matrix(~er + dose) # estrogen and dose effect, without interaction
model.matrix(~er * dose) # estrogen and dose effect, with interaction
beta <- c(beta0, beta.er, beta.dose) # vector of parameters (must match order in design matrix!)
Y <- X %*% beta # syntax: %*% - matrix multiplication
plot(dose, Y)
e <- rnorm(80, mean=0, sd=1)
Y.observed <- Y + e
plot(dose, Y.observed, col=as.numeric(factor(er)))
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- 1
}
# BiocManager is needed to install Bioconductor packages
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# Install eisaR
BiocManager::install("eisaR")
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
txdbFile
clear all
clear
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"),
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"),
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"),
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"), BiocManager::available("EnsDb"))
BiocManager::install("annotationDbi")
2
BiocManager::install("AnnotationDbi")
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
txdb <- AnnotationDbi::loadDb(txdbFile)
#### Packages ####
library(eisaR)
# Load TxDb object
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
BiocManager::install("eisaR")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# Install eisaR
BiocManager::install("eisaR")
# Tutorial: https://bioconductor.org/packages/release/bioc/vignettes/eisaR/inst/doc/eisaR.html
# Documentation: https://bioconductor.org/packages/release/bioc/manuals/eisaR/man/eisaR.pdf
#### Preparing the annotation ####
library(eisaR)
# Load TxDb object
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
# Extract filtered exonic and gene body regions
regS <- getRegionsFromTxDb(txdb = txdb, strandedData = TRUE)
regU <- getRegionsFromTxDb(txdb = txdb, strandedData = FALSE)
lengths(regS)
lengths(regU)
regS$exons
# Exporting to .gtf files
library(rtracklayer)
export(regS$exons, "hg19sub_exons_stranded.gtf")
export(regS$genebodies, "hg19sub_genebodies_stranded.gtf")
#### Quantify RNA-seq alignments in exons and introns
library(QuasR) # QuasR package for indexing and aligning short reads
# Copy sample data from package into current directory
file.copy(system.file(package = "QuasR", "extdata"), ".", recursive = TRUE)
# Align reads to a genome
proj <- qAlign(sampleFile = "extdata/samples_rna_single.txt",
genome = "extdata/hg19sub.fa",
aligner = "Rhisat2", splicedAlignment = TRUE)
alignmentStats(proj)
install.packages("XML")
install.packages("XML")
help(n)
??n
BiocManager::install("broom")
library("cowplot")
BiocManager::install("cowplot")
BiocManager::install("dplyr")
library("ggplot2")
BiocManager::install("knitr")
BiocManager::install("stringr")
help(n)
help(mutate)
help(stopifnot)
help(runif)
help(coef)
help(tidy)
install.packages("tidyverse")
install.packages("devtools")
#### Packages ####
library(DESeq2)
library(glue)
setwd("~/mrc/project/rna-seq")
#### Load data ####
proj <- "GSE69308"
counts <- read.table(glue("processed/{gse}_rawCounts.txt"), header=TRUE, sep='\t',
row.names=1, check.names=FALSE)
#### DESeq2 ####
#### Packages ####
library(DESeq2)
library(glue)
setwd("~/mrc/project/rna-seq")
#### Load data ####
proj <- "GSE69308"
counts <- read.table(glue("processed/{proj}_rawCounts.txt"), header=TRUE, sep='\t',
row.names=1, check.names=FALSE)
#### DESeq2 ####
counts
#### Packages ####
library(DESeq2)
library(glue)
setwd("~/mrc/project/rna-seq")
#### Load data ####
proj <- "GSE69308"
countsTable <- read.table(glue("processed/{proj}_rawCounts.txt"), header=TRUE, sep='\t',
row.names=1, check.names=FALSE)
counts <- countsTable
counts$Length <- NULL
#### DESeq2 ####
counts
dds <- DESeqDataSetFromMatrix(countData=counts)
colData <- data.frame(row.names=colnames(counts),
condition=colnames(counts))
dds <- DESeqDataSetFromMatrix(countData=counts,
colData=colData)
mcols$dds
mcols(dds)
colData <- data.frame(row.names=colnames(counts),
condition=colnames(counts))
dds <- DESeqDataSetFromMatrix(countData=counts,
colData=colData,
design= ~ condition)
dds
dds <- DESeqDataSetFromMatrix(countData=counts,
colData=colData,
design= ~ 1)
dds
mcols(dds)
dds$basepairs <- countsTable[, 'Length']
dds
mcol(dds)
mcols(dds)
counts
colData <- data.frame(row.names=colnames(counts),
condition=colnames(counts))
dds <- DESeqDataSetFromMatrix(countData=counts,
colData=colData,
design= ~ 1)
mcols(dds)$basepairs <- countsTable[, 'Length']
mcols(dds)
dds.fpkm <- fpkm(dds)
dds.fppkm
dds.fpkm
head(dds.fpkm)
mcols(dds)
library(biomaRt)
#### Functions ####
add_ensembl_symbol <- function (table) {
genes <- row.names(table)
if (grepl("ENSG", genes[1], fixed=TRUE)) {
ensemblDataset <- "hsapiens_gene_ensembl"
symbol <- "hgnc_symbol"
} else if (grepl("ENSMUSG", genes[1], fixed=TRUE)) {
ensemblDataset <- "mmusculus_gene_ensembl"
symbol <- "mgi_symbol"
}
mart <- useDataset(ensemblDataset, useMart("ENSEMBL_MART_ENSEMBL", host="http://www.ensembl.org"))
geneList <- getBM(filters="ensembl_gene_id",
attributes=c("ensembl_gene_id", symbol),
values=genes,
mart=mart)
row.names(geneList) <- geneList[, 1]
geneList[, 1] <- NULL
table$geneSymbol <- geneList[, 1][match(rownames(table), rownames(geneList))]
newTable <- table
return(newTable)
}
dds.fpkm <- add_ensembl_symbol(dds.fpkm)
dds.fpkm <- add_ensembl_symbol(dds.fpkm)
dds.fpkm <- add_ensembl_symbol(dds.fpkm)
dds.fpkm <- add_ensembl_symbol(dds.fpkm)
write.table(dds.fpkm,
file=glue("processed/{gse}_fpkm.txt"),
row.names=TRUE, col.names=TRUE, sep="\t")
# Save to output
write.table(dds.fpkm, file=glue("processed/{proj}_fpkm.txt"),
row.names=TRUE, col.names=TRUE, sep="\t")
# Save to output
write.table(dds.fpkm, file=glue("processed/{proj}_fpkm.txt"),
row.names=TRUE, col.names=TRUE, sep="\t", quote=FALSE)
proj <- "GSE147893"
countsTable <- read.table(glue("processed/{proj}_rawCounts.txt"), header=TRUE, sep='\t',
row.names=1, check.names=FALSE)
counts <- countsTable
counts$Length <- NULL
#### DESeq2 ####
# Create DDS object
colData <- data.frame(row.names=colnames(counts),
condition=colnames(counts))
dds <- DESeqDataSetFromMatrix(countData=counts,
colData=colData,
design= ~ 1)
# Add gene length info
mcols(dds)$basepairs <- countsTable[, 'Length']
# Calculate FPKM
dds.fpkm <- fpkm(dds)
# Add gene symbol info
# dds.fpkm <- add_ensembl_symbol(dds.fpkm)
# Save to output
write.table(dds.fpkm, file=glue("processed/{proj}_fpkm.txt"),
row.names=TRUE, col.names=TRUE, sep="\t", quote=FALSE)
